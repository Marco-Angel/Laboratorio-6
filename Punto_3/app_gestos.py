import streamlit as st
import cv2
import time
from hand_detector import HandGestureDetector, GestureType
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="Detector de Gestos de Mano",
    page_icon="ğŸ–ï¸",
    layout="wide"
)

# TÃ­tulo
st.title("ğŸ–ï¸ Detector de Gestos de Mano con MediaPipe")
st.markdown("### Procesamiento en tiempo real con Threading, Mutex y SemÃ¡foros")
st.markdown("---")

# Inicializar detector en session_state
if 'detector' not in st.session_state:
    st.session_state.detector = None
    st.session_state.detector_running = False

# Sidebar - Controles
with st.sidebar:
    st.header("âš™ï¸ Controles")
    
    # Control del detector
    if not st.session_state.detector_running:
        if st.button("ğŸ¥ INICIAR DETECTOR", type="primary", use_container_width=True):
            try:
                st.session_state.detector = HandGestureDetector(max_hands=2)
                st.session_state.detector.start(camera_id=0)
                st.session_state.detector_running = True
                st.success("âœ… Detector iniciado")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Error: {str(e)}")
    else:
        if st.button("ğŸ›‘ DETENER DETECTOR", type="secondary", use_container_width=True):
            if st.session_state.detector:
                st.session_state.detector.stop()
            st.session_state.detector_running = False
            st.session_state.detector = None
            st.success("âœ… Detector detenido")
            st.rerun()
    
    st.markdown("---")
    
    # InformaciÃ³n de gestos detectables
    st.subheader("ğŸ¯ Gestos Detectables")
    st.markdown("""
    - ğŸ‘ **Pulgar Arriba**
    - ğŸ‘ **Pulgar Abajo**
    - âœŒï¸ **Paz** (2 dedos)
    - âœŠ **PuÃ±o** (mano cerrada)
    - ğŸ–ï¸ **Palma Abierta** (5 dedos)
    - â˜ï¸ **Apuntando** (1 dedo)
    - ğŸ‘Œ **OK** (cÃ­rculo)
    """)
    
    st.markdown("---")
    
    # InformaciÃ³n tÃ©cnica
    st.subheader("ğŸ§µ Threading Info")
    
    if st.session_state.detector_running and st.session_state.detector:
        stats = st.session_state.detector.get_statistics()
        st.info(f"""
        **Hilos activos:** {stats['active_threads']}
        
        **Tipos de hilos:**
        - CaptureThread (CÃ¡mara)
        - ProcessThread (MediaPipe)
        - FPSThread (CÃ¡lculo FPS)
        - StatsThread (EstadÃ­sticas)
        
        **SincronizaciÃ³n:**
        - ğŸ”’ Mutex para frames
        - ğŸ”’ Mutex para gestos
        - ğŸ”’ Mutex para estadÃ­sticas
        - ğŸš¦ SemÃ¡foro para cÃ¡mara
        """)
    else:
        st.info("""
        **Hilos a crear:**
        - CaptureThread
        - ProcessThread
        - FPSThread
        - StatsThread
        
        **SincronizaciÃ³n:**
        - ğŸ”’ 3 Mutex (Lock)
        - ğŸš¦ 1 SemÃ¡foro
        """)

# Contenido principal
if st.session_state.detector_running and st.session_state.detector:
    
    # Obtener estadÃ­sticas
    stats = st.session_state.detector.get_statistics()
    gestures = st.session_state.detector.get_current_gestures()
    
    # MÃ©tricas principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ¥ FPS", f"{stats['fps']}")
    
    with col2:
        st.metric("ğŸ§µ Hilos Activos", stats['active_threads'])
    
    with col3:
        st.metric("ğŸ“Š Detecciones Totales", stats['total_detections'])
    
    with col4:
        uptime_mins = int(stats['uptime'] // 60)
        uptime_secs = int(stats['uptime'] % 60)
        st.metric("â±ï¸ Tiempo Activo", f"{uptime_mins}m {uptime_secs}s")
    
    st.markdown("---")
    
    # Video en tiempo real
    col_video, col_info = st.columns([2, 1])
    
    with col_video:
        st.subheader("ğŸ“¹ CÃ¡mara en Vivo")
        video_placeholder = st.empty()
        
        # Obtener y mostrar frame
        frame = st.session_state.detector.get_current_frame()
        if frame is not None:
            # Convertir BGR a RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            video_placeholder.image(frame_rgb, channels="RGB", use_column_width=True)
        else:
            video_placeholder.info("â³ Esperando frames de la cÃ¡mara...")
    
    with col_info:
        st.subheader("ğŸ–ï¸ Gestos Detectados")
        
        if gestures:
            for i, hand in enumerate(gestures):
                with st.container():
                    st.markdown(f"""
                    **Mano {i+1}:** {hand.hand_type}  
                    **Gesto:** {hand.gesture.value}  
                    **Confianza:** {hand.confidence:.1%}
                    """)
                    st.progress(hand.confidence)
                    st.markdown("---")
        else:
            st.info("ğŸ‘‹ Muestra tus manos a la cÃ¡mara")
    
    # GrÃ¡ficos de estadÃ­sticas
    st.markdown("---")
    st.subheader("ğŸ“Š EstadÃ­sticas de Gestos")
    
    col_chart1, col_chart2 = st.columns(2)
    
    with col_chart1:
        # GrÃ¡fico de barras
        gesture_data = {
            'Gesto': list(stats['gesture_count'].keys()),
            'Cantidad': list(stats['gesture_count'].values())
        }
        df_gestures = pd.DataFrame(gesture_data)
        
        # Filtrar solo gestos con detecciones
        df_gestures = df_gestures[df_gestures['Cantidad'] > 0]
        
        if not df_gestures.empty:
            fig_bar = px.bar(
                df_gestures,
                x='Gesto',
                y='Cantidad',
                title='Gestos Detectados (Total)',
                color='Cantidad',
                color_continuous_scale='Viridis'
            )
            fig_bar.update_layout(height=400, showlegend=False)
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("â³ Esperando detecciones...")
    
    with col_chart2:
        # GrÃ¡fico de pastel
        if not df_gestures.empty:
            fig_pie = go.Figure(data=[go.Pie(
                labels=df_gestures['Gesto'],
                values=df_gestures['Cantidad'],
                hole=0.4
            )])
            fig_pie.update_layout(
                title='DistribuciÃ³n de Gestos',
                height=400
            )
            st.plotly_chart(fig_pie, use_container_width=True)
        else:
            st.info("â³ Esperando detecciones...")
    
    # Tabla de hilos
    st.markdown("---")
    st.subheader("ğŸ§µ Estado de los Hilos")
    
    thread_data = {
        'Hilo': ['CaptureThread', 'ProcessThread', 'FPSThread', 'StatsThread'],
        'Estado': ['ğŸŸ¢ Activo'] * 4,
        'FunciÃ³n': [
            'Capturar frames de cÃ¡mara',
            'Procesar con MediaPipe',
            'Calcular FPS',
            'Actualizar estadÃ­sticas'
        ]
    }
    df_threads = pd.DataFrame(thread_data)
    st.dataframe(df_threads, use_container_width=True, hide_index=True)
    
    # InformaciÃ³n tÃ©cnica
    st.markdown("---")
    st.subheader("ğŸ”§ ImplementaciÃ³n TÃ©cnica")
    
    col_left, col_right = st.columns(2)
    
    with col_left:
        st.markdown("""
        ### ğŸ§µ Threading
        - **CaptureThread**: Captura frames a ~100 FPS
        - **ProcessThread**: Procesa con MediaPipe a ~30 FPS
        - **FPSThread**: Calcula frames por segundo
        - **StatsThread**: Actualiza estadÃ­sticas cada segundo
        
        ### ğŸ”’ Secciones CrÃ­ticas
        - **Frame compartido**: Protegido con `frame_lock`
        - **Gestos detectados**: Protegido con `gesture_lock`
        - **EstadÃ­sticas**: Protegido con `stats_lock`
        """)
    
    with col_right:
        st.markdown("""
        ### ğŸ” Mutex (Lock)
        ```python
        with self.gesture_lock:
            self.current_gestures = detected
            self.gesture_count[gesture] += 1
        ```
        
        ### ğŸš¦ SemÃ¡foro
        ```python
        camera_semaphore = Semaphore(1)
        # Solo un hilo accede a cÃ¡mara
        camera_semaphore.acquire()
        # ... usar cÃ¡mara ...
        camera_semaphore.release()
        ```
        """)
    
    # Auto-refresh
    time.sleep(0.05)
    st.rerun()

else:
    # Pantalla de inicio
    st.info("ğŸ‘† Presiona 'ğŸ¥ INICIAR DETECTOR' en la barra lateral para comenzar")
    
    st.markdown("""
    ## ğŸ¯ Â¿CÃ³mo funciona?
    
    Este detector utiliza **MediaPipe** de Google para detectar manos en tiempo real y reconocer gestos.
    
    ### ğŸ§µ **Threading Implementado:**
    
    1. **Hilo de Captura**: Lee frames de la cÃ¡mara constantemente
    2. **Hilo de Procesamiento**: Analiza cada frame con MediaPipe
    3. **Hilo de FPS**: Calcula los frames por segundo
    4. **Hilo de EstadÃ­sticas**: Mantiene conteo de gestos detectados
    
    ### ğŸ”’ **SincronizaciÃ³n:**
    
    - **Mutex (Lock)**: Protege datos compartidos entre hilos
    - **SemÃ¡foro**: Controla acceso exclusivo a la cÃ¡mara
    - **Secciones CrÃ­ticas**: ActualizaciÃ³n segura de contadores
    
    ### ğŸ–ï¸ **Gestos Reconocidos:**
    
    - Pulgar arriba/abajo
    - SeÃ±al de paz (âœŒï¸)
    - PuÃ±o cerrado
    - Palma abierta
    - Apuntando con el dedo
    - OK (ğŸ‘Œ)
    
    """)
    
    # Imagen de ejemplo
    st.image("https://via.placeholder.com/800x400/4A90E2/FFFFFF?text=Presiona+INICIAR+para+activar+la+c%C3%A1mara", 
             use_container_width=True)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    ğŸ–ï¸ Powered by MediaPipe + OpenCV + Streamlit + Threading
</div>
""", unsafe_allow_html=True)